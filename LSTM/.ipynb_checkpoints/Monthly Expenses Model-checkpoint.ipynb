{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a173b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac3502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv('Data/sales dataset.csv')\n",
    "sales_data['salesDate'] = pd.to_datetime(sales_data['salesDate'], infer_datetime_format=True)\n",
    "selected_columns1 =['salesAmount', 'salesDate']\n",
    "sales_data = sales_data[selected_columns1]\n",
    "##########################################################################\n",
    "expenses_data = pd.read_csv('Data/expenses dataset.csv')\n",
    "expenses_data['expenseDate'] = pd.to_datetime(expenses_data['expenseDate'], infer_datetime_format=True)\n",
    "selected_columns =['expenseAmount', 'expenseDate']\n",
    "expenses_data = expenses_data[selected_columns]\n",
    "##########################################################################\n",
    "# print('Shape of expenses data', expenses_data.shape)\n",
    "# print('Shape of sales data', sales_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b60e512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Berlin\\AppData\\Local\\Temp\\ipykernel_7656\\1523643852.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['expenseDate'] = pd.to_datetime(df['expenseDate'], dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expenseAmount</th>\n",
       "      <th>expenseDate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenseDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-12</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>2020-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-12</th>\n",
       "      <td>5500.0</td>\n",
       "      <td>2020-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-12</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>2020-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-12</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>2020-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-12</th>\n",
       "      <td>1400.0</td>\n",
       "      <td>2020-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-09</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2023-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-09</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2023-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-09</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>2023-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-09</th>\n",
       "      <td>11500.0</td>\n",
       "      <td>2023-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-09</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2023-11-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6622 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             expenseAmount expenseDate\n",
       "expenseDate                           \n",
       "2020-05-12         15000.0  2020-05-12\n",
       "2020-05-12          5500.0  2020-05-12\n",
       "2020-05-12         10000.0  2020-05-12\n",
       "2020-05-12         12000.0  2020-05-12\n",
       "2020-05-12          1400.0  2020-05-12\n",
       "...                    ...         ...\n",
       "2023-11-09           200.0  2023-11-09\n",
       "2023-11-09           500.0  2023-11-09\n",
       "2023-11-09          6000.0  2023-11-09\n",
       "2023-11-09         11500.0  2023-11-09\n",
       "2023-11-09          1000.0  2023-11-09\n",
       "\n",
       "[6622 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['expenseDate'] = pd.to_datetime(df['expenseDate'], dayfirst=True)\n",
    "df.index = df['expenseDate']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01701960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Berlin\\AppData\\Local\\Temp\\ipykernel_7656\\949219160.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Year'] = df['expenseDate'].dt.year\n",
      "C:\\Users\\Berlin\\AppData\\Local\\Temp\\ipykernel_7656\\949219160.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Month'] = df['expenseDate'].dt.month\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>expenseAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>462850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>958734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>767630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>1233400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>2379730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>2018480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>2115684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>1776590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2402525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>2576390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>2953250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>2788040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>2288517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>3403150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>2413250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>2590300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>2907560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>4512300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>9266557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>2862578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>4357935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>4138127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>4763205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>2448500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>4532500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>5117140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>4269108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>2951285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>3023914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>3484350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>2935800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2462150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>4652250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>1050750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>546350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>1654105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>2195350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>1529350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>1549450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>2304875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>3404500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>2553430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>464051.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Month  expenseAmount\n",
       "0   2020      5       462850.0\n",
       "1   2020      6       958734.0\n",
       "2   2020      7       767630.0\n",
       "3   2020      8      1233400.0\n",
       "4   2020      9      2379730.0\n",
       "5   2020     10      2018480.0\n",
       "6   2020     11      2115684.0\n",
       "7   2020     12      1776590.0\n",
       "8   2021      1      2402525.0\n",
       "9   2021      2      2576390.0\n",
       "10  2021      3      2953250.0\n",
       "11  2021      4      2788040.0\n",
       "12  2021      5      2288517.0\n",
       "13  2021      6      3403150.0\n",
       "14  2021      7      2413250.0\n",
       "15  2021      8      2590300.0\n",
       "16  2021      9      2907560.0\n",
       "17  2021     10      4512300.0\n",
       "18  2021     11      9266557.0\n",
       "19  2021     12      2862578.0\n",
       "20  2022      1      4357935.0\n",
       "21  2022      2      4138127.0\n",
       "22  2022      3      4763205.0\n",
       "23  2022      4      2448500.0\n",
       "24  2022      5      4532500.0\n",
       "25  2022      6      5117140.0\n",
       "26  2022      7      4269108.0\n",
       "27  2022      8      2951285.0\n",
       "28  2022      9      3023914.0\n",
       "29  2022     10      3484350.0\n",
       "30  2022     11      2935800.0\n",
       "31  2022     12      2462150.0\n",
       "32  2023      1      4652250.0\n",
       "33  2023      2      1050750.0\n",
       "34  2023      3       546350.0\n",
       "35  2023      4      1654105.0\n",
       "36  2023      5      2195350.0\n",
       "37  2023      6      1529350.0\n",
       "38  2023      7      1549450.0\n",
       "39  2023      8      2304875.0\n",
       "40  2023      9      3404500.0\n",
       "41  2023     10      2553430.0\n",
       "42  2023     11       464051.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Year'] = df['expenseDate'].dt.year\n",
    "df['Month'] = df['expenseDate'].dt.month\n",
    "###################\n",
    "df_monthly = df.groupby(['Year', 'Month'])['expenseAmount'].sum().reset_index()\n",
    "###################\n",
    "# df_monthly = df_monthly.set_index('Month')\n",
    "df_monthly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46917e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      462850.0\n",
       "1      958734.0\n",
       "2      767630.0\n",
       "3     1233400.0\n",
       "4     2379730.0\n",
       "5     2018480.0\n",
       "6     2115684.0\n",
       "7     1776590.0\n",
       "8     2402525.0\n",
       "9     2576390.0\n",
       "10    2953250.0\n",
       "11    2788040.0\n",
       "12    2288517.0\n",
       "13    3403150.0\n",
       "14    2413250.0\n",
       "15    2590300.0\n",
       "16    2907560.0\n",
       "17    4512300.0\n",
       "18    9266557.0\n",
       "19    2862578.0\n",
       "20    4357935.0\n",
       "21    4138127.0\n",
       "22    4763205.0\n",
       "23    2448500.0\n",
       "24    4532500.0\n",
       "25    5117140.0\n",
       "26    4269108.0\n",
       "27    2951285.0\n",
       "28    3023914.0\n",
       "29    3484350.0\n",
       "30    2935800.0\n",
       "31    2462150.0\n",
       "32    4652250.0\n",
       "33    1050750.0\n",
       "34     546350.0\n",
       "35    1654105.0\n",
       "36    2195350.0\n",
       "37    1529350.0\n",
       "38    1549450.0\n",
       "39    2304875.0\n",
       "40    3404500.0\n",
       "41    2553430.0\n",
       "42     464051.0\n",
       "Name: expenseAmount, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expenses = df_monthly['expenseAmount']\n",
    "expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "171cdfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 462850.],\n",
       "       [ 958734.],\n",
       "       [ 767630.],\n",
       "       [1233400.],\n",
       "       [2379730.],\n",
       "       [2018480.],\n",
       "       [2115684.],\n",
       "       [1776590.],\n",
       "       [2402525.],\n",
       "       [2576390.],\n",
       "       [2953250.],\n",
       "       [2788040.],\n",
       "       [2288517.],\n",
       "       [3403150.],\n",
       "       [2413250.],\n",
       "       [2590300.],\n",
       "       [2907560.],\n",
       "       [4512300.],\n",
       "       [9266557.],\n",
       "       [2862578.],\n",
       "       [4357935.],\n",
       "       [4138127.],\n",
       "       [4763205.],\n",
       "       [2448500.],\n",
       "       [4532500.],\n",
       "       [5117140.],\n",
       "       [4269108.],\n",
       "       [2951285.],\n",
       "       [3023914.],\n",
       "       [3484350.],\n",
       "       [2935800.],\n",
       "       [2462150.],\n",
       "       [4652250.],\n",
       "       [1050750.],\n",
       "       [ 546350.],\n",
       "       [1654105.],\n",
       "       [2195350.],\n",
       "       [1529350.],\n",
       "       [1549450.],\n",
       "       [2304875.],\n",
       "       [3404500.],\n",
       "       [2553430.],\n",
       "       [ 464051.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expenses = np.array(expenses).reshape(-1,1)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(expenses)\n",
    "expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415ce5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y(df, window_size=4):\n",
    "    df_as_np = df\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np) - window_size):\n",
    "        row = [[a] for a in df_as_np[i:i+window_size]]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i+window_size]\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78a1c940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39, 4, 1, 1), (39, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOW_SIZE = 4\n",
    "X, y = df_to_X_y(scaled_data, WINDOW_SIZE)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83c2bebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        ]],\n",
       "\n",
       "        [[0.05632673]],\n",
       "\n",
       "        [[0.03461951]],\n",
       "\n",
       "        [[0.08752563]]],\n",
       "\n",
       "\n",
       "       [[[0.05632673]],\n",
       "\n",
       "        [[0.03461951]],\n",
       "\n",
       "        [[0.08752563]],\n",
       "\n",
       "        [[0.21773555]]],\n",
       "\n",
       "\n",
       "       [[[0.03461951]],\n",
       "\n",
       "        [[0.08752563]],\n",
       "\n",
       "        [[0.21773555]],\n",
       "\n",
       "        [[0.1767017 ]]],\n",
       "\n",
       "\n",
       "       [[[0.08752563]],\n",
       "\n",
       "        [[0.21773555]],\n",
       "\n",
       "        [[0.1767017 ]],\n",
       "\n",
       "        [[0.18774296]]],\n",
       "\n",
       "\n",
       "       [[[0.21773555]],\n",
       "\n",
       "        [[0.1767017 ]],\n",
       "\n",
       "        [[0.18774296]],\n",
       "\n",
       "        [[0.14922578]]],\n",
       "\n",
       "\n",
       "       [[[0.1767017 ]],\n",
       "\n",
       "        [[0.18774296]],\n",
       "\n",
       "        [[0.14922578]],\n",
       "\n",
       "        [[0.2203248 ]]],\n",
       "\n",
       "\n",
       "       [[[0.18774296]],\n",
       "\n",
       "        [[0.14922578]],\n",
       "\n",
       "        [[0.2203248 ]],\n",
       "\n",
       "        [[0.24007387]]],\n",
       "\n",
       "\n",
       "       [[[0.14922578]],\n",
       "\n",
       "        [[0.2203248 ]],\n",
       "\n",
       "        [[0.24007387]],\n",
       "\n",
       "        [[0.28288084]]],\n",
       "\n",
       "\n",
       "       [[[0.2203248 ]],\n",
       "\n",
       "        [[0.24007387]],\n",
       "\n",
       "        [[0.28288084]],\n",
       "\n",
       "        [[0.26411488]]],\n",
       "\n",
       "\n",
       "       [[[0.24007387]],\n",
       "\n",
       "        [[0.28288084]],\n",
       "\n",
       "        [[0.26411488]],\n",
       "\n",
       "        [[0.2073748 ]]],\n",
       "\n",
       "\n",
       "       [[[0.28288084]],\n",
       "\n",
       "        [[0.26411488]],\n",
       "\n",
       "        [[0.2073748 ]],\n",
       "\n",
       "        [[0.33398431]]],\n",
       "\n",
       "\n",
       "       [[[0.26411488]],\n",
       "\n",
       "        [[0.2073748 ]],\n",
       "\n",
       "        [[0.33398431]],\n",
       "\n",
       "        [[0.22154304]]],\n",
       "\n",
       "\n",
       "       [[[0.2073748 ]],\n",
       "\n",
       "        [[0.33398431]],\n",
       "\n",
       "        [[0.22154304]],\n",
       "\n",
       "        [[0.24165389]]],\n",
       "\n",
       "\n",
       "       [[[0.33398431]],\n",
       "\n",
       "        [[0.22154304]],\n",
       "\n",
       "        [[0.24165389]],\n",
       "\n",
       "        [[0.27769098]]],\n",
       "\n",
       "\n",
       "       [[[0.22154304]],\n",
       "\n",
       "        [[0.24165389]],\n",
       "\n",
       "        [[0.27769098]],\n",
       "\n",
       "        [[0.45997101]]],\n",
       "\n",
       "\n",
       "       [[[0.24165389]],\n",
       "\n",
       "        [[0.27769098]],\n",
       "\n",
       "        [[0.45997101]],\n",
       "\n",
       "        [[1.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.27769098]],\n",
       "\n",
       "        [[0.45997101]],\n",
       "\n",
       "        [[1.        ]],\n",
       "\n",
       "        [[0.27258154]]],\n",
       "\n",
       "\n",
       "       [[[0.45997101]],\n",
       "\n",
       "        [[1.        ]],\n",
       "\n",
       "        [[0.27258154]],\n",
       "\n",
       "        [[0.44243692]]],\n",
       "\n",
       "\n",
       "       [[[1.        ]],\n",
       "\n",
       "        [[0.27258154]],\n",
       "\n",
       "        [[0.44243692]],\n",
       "\n",
       "        [[0.41746925]]],\n",
       "\n",
       "\n",
       "       [[[0.27258154]],\n",
       "\n",
       "        [[0.44243692]],\n",
       "\n",
       "        [[0.41746925]],\n",
       "\n",
       "        [[0.48847094]]],\n",
       "\n",
       "\n",
       "       [[[0.44243692]],\n",
       "\n",
       "        [[0.41746925]],\n",
       "\n",
       "        [[0.48847094]],\n",
       "\n",
       "        [[0.22554703]]],\n",
       "\n",
       "\n",
       "       [[[0.41746925]],\n",
       "\n",
       "        [[0.48847094]],\n",
       "\n",
       "        [[0.22554703]],\n",
       "\n",
       "        [[0.4622655 ]]],\n",
       "\n",
       "\n",
       "       [[[0.48847094]],\n",
       "\n",
       "        [[0.22554703]],\n",
       "\n",
       "        [[0.4622655 ]],\n",
       "\n",
       "        [[0.52867389]]],\n",
       "\n",
       "\n",
       "       [[[0.22554703]],\n",
       "\n",
       "        [[0.4622655 ]],\n",
       "\n",
       "        [[0.52867389]],\n",
       "\n",
       "        [[0.43234719]]],\n",
       "\n",
       "\n",
       "       [[[0.4622655 ]],\n",
       "\n",
       "        [[0.52867389]],\n",
       "\n",
       "        [[0.43234719]],\n",
       "\n",
       "        [[0.28265764]]],\n",
       "\n",
       "\n",
       "       [[[0.52867389]],\n",
       "\n",
       "        [[0.43234719]],\n",
       "\n",
       "        [[0.28265764]],\n",
       "\n",
       "        [[0.29090746]]],\n",
       "\n",
       "\n",
       "       [[[0.43234719]],\n",
       "\n",
       "        [[0.28265764]],\n",
       "\n",
       "        [[0.29090746]],\n",
       "\n",
       "        [[0.3432077 ]]],\n",
       "\n",
       "\n",
       "       [[[0.28265764]],\n",
       "\n",
       "        [[0.29090746]],\n",
       "\n",
       "        [[0.3432077 ]],\n",
       "\n",
       "        [[0.28089872]]],\n",
       "\n",
       "\n",
       "       [[[0.29090746]],\n",
       "\n",
       "        [[0.3432077 ]],\n",
       "\n",
       "        [[0.28089872]],\n",
       "\n",
       "        [[0.22709752]]],\n",
       "\n",
       "\n",
       "       [[[0.3432077 ]],\n",
       "\n",
       "        [[0.28089872]],\n",
       "\n",
       "        [[0.22709752]],\n",
       "\n",
       "        [[0.47586772]]],\n",
       "\n",
       "\n",
       "       [[[0.28089872]],\n",
       "\n",
       "        [[0.22709752]],\n",
       "\n",
       "        [[0.47586772]],\n",
       "\n",
       "        [[0.06677869]]],\n",
       "\n",
       "\n",
       "       [[[0.22709752]],\n",
       "\n",
       "        [[0.47586772]],\n",
       "\n",
       "        [[0.06677869]],\n",
       "\n",
       "        [[0.00948464]]],\n",
       "\n",
       "\n",
       "       [[[0.47586772]],\n",
       "\n",
       "        [[0.06677869]],\n",
       "\n",
       "        [[0.00948464]],\n",
       "\n",
       "        [[0.13531289]]],\n",
       "\n",
       "\n",
       "       [[[0.06677869]],\n",
       "\n",
       "        [[0.00948464]],\n",
       "\n",
       "        [[0.13531289]],\n",
       "\n",
       "        [[0.1967921 ]]],\n",
       "\n",
       "\n",
       "       [[[0.00948464]],\n",
       "\n",
       "        [[0.13531289]],\n",
       "\n",
       "        [[0.1967921 ]],\n",
       "\n",
       "        [[0.12114215]]],\n",
       "\n",
       "\n",
       "       [[[0.13531289]],\n",
       "\n",
       "        [[0.1967921 ]],\n",
       "\n",
       "        [[0.12114215]],\n",
       "\n",
       "        [[0.12342528]]],\n",
       "\n",
       "\n",
       "       [[[0.1967921 ]],\n",
       "\n",
       "        [[0.12114215]],\n",
       "\n",
       "        [[0.12342528]],\n",
       "\n",
       "        [[0.20923288]]],\n",
       "\n",
       "\n",
       "       [[[0.12114215]],\n",
       "\n",
       "        [[0.12342528]],\n",
       "\n",
       "        [[0.20923288]],\n",
       "\n",
       "        [[0.33413765]]],\n",
       "\n",
       "\n",
       "       [[[0.12342528]],\n",
       "\n",
       "        [[0.20923288]],\n",
       "\n",
       "        [[0.33413765]],\n",
       "\n",
       "        [[0.23746588]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f791ad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.17735552e-01],\n",
       "       [1.76701701e-01],\n",
       "       [1.87742959e-01],\n",
       "       [1.49225775e-01],\n",
       "       [2.20324802e-01],\n",
       "       [2.40073869e-01],\n",
       "       [2.82880836e-01],\n",
       "       [2.64114878e-01],\n",
       "       [2.07374802e-01],\n",
       "       [3.33984309e-01],\n",
       "       [2.21543039e-01],\n",
       "       [2.41653885e-01],\n",
       "       [2.77690977e-01],\n",
       "       [4.59971010e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.72581539e-01],\n",
       "       [4.42436919e-01],\n",
       "       [4.17469255e-01],\n",
       "       [4.88470936e-01],\n",
       "       [2.25547034e-01],\n",
       "       [4.62265498e-01],\n",
       "       [5.28673887e-01],\n",
       "       [4.32347192e-01],\n",
       "       [2.82657635e-01],\n",
       "       [2.90907455e-01],\n",
       "       [3.43207696e-01],\n",
       "       [2.80898717e-01],\n",
       "       [2.27097517e-01],\n",
       "       [4.75867723e-01],\n",
       "       [6.67786877e-02],\n",
       "       [9.48464096e-03],\n",
       "       [1.35312886e-01],\n",
       "       [1.96792101e-01],\n",
       "       [1.21142151e-01],\n",
       "       [1.23425280e-01],\n",
       "       [2.09232883e-01],\n",
       "       [3.34137654e-01],\n",
       "       [2.37465877e-01],\n",
       "       [1.36419806e-04]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b938ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = X[:37], y[:37]\n",
    "# X_val, y_val = X[37:39], y[37:39]\n",
    "# X_test, y_test = X[39:], y[39:]\n",
    "# X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a361ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94b61c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.27769098]],\n",
       "\n",
       "        [[0.45997101]],\n",
       "\n",
       "        [[1.        ]],\n",
       "\n",
       "        [[0.27258154]]],\n",
       "\n",
       "\n",
       "       [[[0.2073748 ]],\n",
       "\n",
       "        [[0.33398431]],\n",
       "\n",
       "        [[0.22154304]],\n",
       "\n",
       "        [[0.24165389]]],\n",
       "\n",
       "\n",
       "       [[[0.27258154]],\n",
       "\n",
       "        [[0.44243692]],\n",
       "\n",
       "        [[0.41746925]],\n",
       "\n",
       "        [[0.48847094]]],\n",
       "\n",
       "\n",
       "       [[[0.24007387]],\n",
       "\n",
       "        [[0.28288084]],\n",
       "\n",
       "        [[0.26411488]],\n",
       "\n",
       "        [[0.2073748 ]]],\n",
       "\n",
       "\n",
       "       [[[0.47586772]],\n",
       "\n",
       "        [[0.06677869]],\n",
       "\n",
       "        [[0.00948464]],\n",
       "\n",
       "        [[0.13531289]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.05632673]],\n",
       "\n",
       "        [[0.03461951]],\n",
       "\n",
       "        [[0.08752563]]],\n",
       "\n",
       "\n",
       "       [[[0.52867389]],\n",
       "\n",
       "        [[0.43234719]],\n",
       "\n",
       "        [[0.28265764]],\n",
       "\n",
       "        [[0.29090746]]],\n",
       "\n",
       "\n",
       "       [[[0.1767017 ]],\n",
       "\n",
       "        [[0.18774296]],\n",
       "\n",
       "        [[0.14922578]],\n",
       "\n",
       "        [[0.2203248 ]]],\n",
       "\n",
       "\n",
       "       [[[0.26411488]],\n",
       "\n",
       "        [[0.2073748 ]],\n",
       "\n",
       "        [[0.33398431]],\n",
       "\n",
       "        [[0.22154304]]],\n",
       "\n",
       "\n",
       "       [[[0.05632673]],\n",
       "\n",
       "        [[0.03461951]],\n",
       "\n",
       "        [[0.08752563]],\n",
       "\n",
       "        [[0.21773555]]],\n",
       "\n",
       "\n",
       "       [[[0.12114215]],\n",
       "\n",
       "        [[0.12342528]],\n",
       "\n",
       "        [[0.20923288]],\n",
       "\n",
       "        [[0.33413765]]],\n",
       "\n",
       "\n",
       "       [[[0.41746925]],\n",
       "\n",
       "        [[0.48847094]],\n",
       "\n",
       "        [[0.22554703]],\n",
       "\n",
       "        [[0.4622655 ]]],\n",
       "\n",
       "\n",
       "       [[[0.03461951]],\n",
       "\n",
       "        [[0.08752563]],\n",
       "\n",
       "        [[0.21773555]],\n",
       "\n",
       "        [[0.1767017 ]]],\n",
       "\n",
       "\n",
       "       [[[0.3432077 ]],\n",
       "\n",
       "        [[0.28089872]],\n",
       "\n",
       "        [[0.22709752]],\n",
       "\n",
       "        [[0.47586772]]],\n",
       "\n",
       "\n",
       "       [[[0.13531289]],\n",
       "\n",
       "        [[0.1967921 ]],\n",
       "\n",
       "        [[0.12114215]],\n",
       "\n",
       "        [[0.12342528]]],\n",
       "\n",
       "\n",
       "       [[[0.08752563]],\n",
       "\n",
       "        [[0.21773555]],\n",
       "\n",
       "        [[0.1767017 ]],\n",
       "\n",
       "        [[0.18774296]]],\n",
       "\n",
       "\n",
       "       [[[0.00948464]],\n",
       "\n",
       "        [[0.13531289]],\n",
       "\n",
       "        [[0.1967921 ]],\n",
       "\n",
       "        [[0.12114215]]],\n",
       "\n",
       "\n",
       "       [[[0.22554703]],\n",
       "\n",
       "        [[0.4622655 ]],\n",
       "\n",
       "        [[0.52867389]],\n",
       "\n",
       "        [[0.43234719]]],\n",
       "\n",
       "\n",
       "       [[[0.22709752]],\n",
       "\n",
       "        [[0.47586772]],\n",
       "\n",
       "        [[0.06677869]],\n",
       "\n",
       "        [[0.00948464]]],\n",
       "\n",
       "\n",
       "       [[[0.28288084]],\n",
       "\n",
       "        [[0.26411488]],\n",
       "\n",
       "        [[0.2073748 ]],\n",
       "\n",
       "        [[0.33398431]]],\n",
       "\n",
       "\n",
       "       [[[0.48847094]],\n",
       "\n",
       "        [[0.22554703]],\n",
       "\n",
       "        [[0.4622655 ]],\n",
       "\n",
       "        [[0.52867389]]],\n",
       "\n",
       "\n",
       "       [[[1.        ]],\n",
       "\n",
       "        [[0.27258154]],\n",
       "\n",
       "        [[0.44243692]],\n",
       "\n",
       "        [[0.41746925]]],\n",
       "\n",
       "\n",
       "       [[[0.44243692]],\n",
       "\n",
       "        [[0.41746925]],\n",
       "\n",
       "        [[0.48847094]],\n",
       "\n",
       "        [[0.22554703]]],\n",
       "\n",
       "\n",
       "       [[[0.14922578]],\n",
       "\n",
       "        [[0.2203248 ]],\n",
       "\n",
       "        [[0.24007387]],\n",
       "\n",
       "        [[0.28288084]]],\n",
       "\n",
       "\n",
       "       [[[0.22154304]],\n",
       "\n",
       "        [[0.24165389]],\n",
       "\n",
       "        [[0.27769098]],\n",
       "\n",
       "        [[0.45997101]]],\n",
       "\n",
       "\n",
       "       [[[0.29090746]],\n",
       "\n",
       "        [[0.3432077 ]],\n",
       "\n",
       "        [[0.28089872]],\n",
       "\n",
       "        [[0.22709752]]],\n",
       "\n",
       "\n",
       "       [[[0.12342528]],\n",
       "\n",
       "        [[0.20923288]],\n",
       "\n",
       "        [[0.33413765]],\n",
       "\n",
       "        [[0.23746588]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f42c0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.42436919e-01],\n",
       "       [2.77690977e-01],\n",
       "       [2.25547034e-01],\n",
       "       [3.33984309e-01],\n",
       "       [1.96792101e-01],\n",
       "       [2.17735552e-01],\n",
       "       [3.43207696e-01],\n",
       "       [2.40073869e-01],\n",
       "       [2.41653885e-01],\n",
       "       [1.76701701e-01],\n",
       "       [2.37465877e-01],\n",
       "       [5.28673887e-01],\n",
       "       [1.87742959e-01],\n",
       "       [6.67786877e-02],\n",
       "       [2.09232883e-01],\n",
       "       [1.49225775e-01],\n",
       "       [1.23425280e-01],\n",
       "       [2.82657635e-01],\n",
       "       [1.35312886e-01],\n",
       "       [2.21543039e-01],\n",
       "       [4.32347192e-01],\n",
       "       [4.88470936e-01],\n",
       "       [4.62265498e-01],\n",
       "       [2.64114878e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.75867723e-01],\n",
       "       [1.36419806e-04]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dd51ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f775a1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2e9162f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a80d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc543baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "615077d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07023790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                16896     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17425 (68.07 KB)\n",
      "Trainable params: 17425 (68.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((4,1)))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(8, 'relu'))\n",
    "model.add(Dense(1, 'linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13c8901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint('Models/Expenses Day Prediction Model/', save_best_only=True)\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.00001), metrics = [RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2946103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0280 - root_mean_squared_error: 0.1673INFO:tensorflow:Assets written to: Models/Expenses Day Prediction Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/Expenses Day Prediction Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 17s 17s/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0279 - root_mean_squared_error: 0.1672 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 191/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1064\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1064\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1064\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1064\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1068\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1068\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1068\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1068\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1114\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1114\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1114\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1114\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f378646770>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, callbacks=[cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bfb93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('Models/Expenses Day Prediction Model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a6c2ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Predictions</th>\n",
       "      <th>Actuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4421412.500</td>\n",
       "      <td>4357935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2967364.500</td>\n",
       "      <td>2907560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3799800.750</td>\n",
       "      <td>2448500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2960287.500</td>\n",
       "      <td>3403150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2568648.750</td>\n",
       "      <td>2195350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1826299.125</td>\n",
       "      <td>2379730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3765603.750</td>\n",
       "      <td>3484350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2579648.750</td>\n",
       "      <td>2576390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2997393.500</td>\n",
       "      <td>2590300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2092857.625</td>\n",
       "      <td>2018480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2613587.500</td>\n",
       "      <td>2553430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3796379.000</td>\n",
       "      <td>5117140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2264546.000</td>\n",
       "      <td>2115684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3378363.000</td>\n",
       "      <td>1050750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2382411.250</td>\n",
       "      <td>2304875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2489754.000</td>\n",
       "      <td>1776590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2205541.500</td>\n",
       "      <td>1549450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3848675.500</td>\n",
       "      <td>2951285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2729854.000</td>\n",
       "      <td>1654105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3066123.250</td>\n",
       "      <td>2413250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3919120.000</td>\n",
       "      <td>4269108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4665238.000</td>\n",
       "      <td>4763205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3821645.000</td>\n",
       "      <td>4532500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2782160.750</td>\n",
       "      <td>2788040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3182244.500</td>\n",
       "      <td>9266557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3176077.500</td>\n",
       "      <td>4652250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2803647.250</td>\n",
       "      <td>464051.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Train Predictions    Actuals\n",
       "0         4421412.500  4357935.0\n",
       "1         2967364.500  2907560.0\n",
       "2         3799800.750  2448500.0\n",
       "3         2960287.500  3403150.0\n",
       "4         2568648.750  2195350.0\n",
       "5         1826299.125  2379730.0\n",
       "6         3765603.750  3484350.0\n",
       "7         2579648.750  2576390.0\n",
       "8         2997393.500  2590300.0\n",
       "9         2092857.625  2018480.0\n",
       "10        2613587.500  2553430.0\n",
       "11        3796379.000  5117140.0\n",
       "12        2264546.000  2115684.0\n",
       "13        3378363.000  1050750.0\n",
       "14        2382411.250  2304875.0\n",
       "15        2489754.000  1776590.0\n",
       "16        2205541.500  1549450.0\n",
       "17        3848675.500  2951285.0\n",
       "18        2729854.000  1654105.0\n",
       "19        3066123.250  2413250.0\n",
       "20        3919120.000  4269108.0\n",
       "21        4665238.000  4763205.0\n",
       "22        3821645.000  4532500.0\n",
       "23        2782160.750  2788040.0\n",
       "24        3182244.500  9266557.0\n",
       "25        3176077.500  4652250.0\n",
       "26        2803647.250   464051.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions = model.predict(X_train)\n",
    "predictions = scaler.inverse_transform(train_predictions).flatten()\n",
    "train_target = scaler.inverse_transform(y_train).flatten()\n",
    "train_results = pd.DataFrame(data={'Train Predictions': predictions, 'Actuals':train_target})\n",
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1833d1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation Predictions</th>\n",
       "      <th>Actuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4719419.50</td>\n",
       "      <td>4138127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4164275.00</td>\n",
       "      <td>2862578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2112222.25</td>\n",
       "      <td>1529350.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Validation Predictions    Actuals\n",
       "0              4719419.50  4138127.0\n",
       "1              4164275.00  2862578.0\n",
       "2              2112222.25  1529350.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions = model.predict(X_val)\n",
    "val_results = scaler.inverse_transform(val_predictions).flatten()\n",
    "val_target = scaler.inverse_transform(y_val).flatten()\n",
    "validation_results = pd.DataFrame(data={'Validation Predictions': val_results, 'Actuals':val_target})\n",
    "validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f991aaaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 616, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm' (type LSTM):\n      â€¢ inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      â€¢ mask=None\n      â€¢ training=False\n      â€¢ initial_state=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.05632673\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.03461951\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.08752563\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filef3rax_i7.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Berlin\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 616, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm' (type LSTM):\n      â€¢ inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      â€¢ mask=None\n      â€¢ training=False\n      â€¢ initial_state=None\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict([[[0.        ]],\n",
    "\n",
    "        [[0.05632673]],\n",
    "\n",
    "        [[0.03461951]],\n",
    "\n",
    "        [[0.08752563]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c79d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
